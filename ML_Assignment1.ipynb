{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushalkuma-r/Machine-Learning-Course/blob/main/ML_Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kerUYJ7b8R_Z"
      },
      "source": [
        "## Import tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "kWbwuuZf8R_c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cDAwyHg8R_e"
      },
      "source": [
        "## Get the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "oHzg_iUV8R_e"
      },
      "outputs": [],
      "source": [
        "visitors_df=pd.read_csv(\"https://raw.githubusercontent.com/kaushalkuma-r/Machine-Learning-Course/main/visitors-covid.csv\")\n",
        "covid_df=pd.read_csv(\"https://raw.githubusercontent.com/kaushalkuma-r/Machine-Learning-Course/main/covid-data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "GTTRyC648R_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50212a73-d8fa-4a5e-a7fa-15b227d77bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        }
      ],
      "source": [
        "covid_df['date']=pd.to_datetime(covid_df['date'])\n",
        "visitors_df['Day']=pd.to_datetime(visitors_df['Day'])\n",
        "covid_df=covid_df[['iso_code', 'continent', 'location', 'date','new_cases']]\n",
        "covid_df=covid_df[covid_df['location']=='India']\n",
        "visitors_df=visitors_df[visitors_df['Entity']=='India']\n",
        "visitors_df.rename(columns={'Day':'date'},inplace=True)\n",
        "covid_merged=pd.merge(covid_df, visitors_df, on='date')\n",
        "final_df=covid_merged.drop(columns=['iso_code', 'continent', 'location', 'date','Entity','Code'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "0pawhIlt8R_f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "5051cd6f-b4a8-4674-8074-3ad7a8ee229c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     new_cases  retail_and_recreation  grocery_and_pharmacy  residential  \\\n",
              "0          0.0                  0.667                 1.667        0.000   \n",
              "1          0.0                  0.500                 1.750        0.000   \n",
              "2          0.0                  0.400                 1.800        0.200   \n",
              "3          0.0                  0.500                 2.000        0.000   \n",
              "4          0.0                 -0.143                 1.714        0.714   \n",
              "..         ...                    ...                   ...          ...   \n",
              "466   173790.0                -61.714               -25.000       24.143   \n",
              "467   165553.0                -61.286               -24.429       23.714   \n",
              "468   152734.0                -61.143               -24.714       23.714   \n",
              "469   127510.0                -60.143               -23.429       23.286   \n",
              "470   132788.0                -58.714               -21.143       22.714   \n",
              "\n",
              "     transit_stations   parks  workplaces  \n",
              "0               2.000   3.000       3.000  \n",
              "1               2.000   3.250       3.000  \n",
              "2               1.800   2.800       3.200  \n",
              "3               2.333   3.167       3.333  \n",
              "4               1.429   3.571       0.143  \n",
              "..                ...     ...         ...  \n",
              "466           -49.143 -41.000     -45.429  \n",
              "467           -48.714 -40.000     -44.571  \n",
              "468           -49.000 -39.143     -44.286  \n",
              "469           -48.286 -38.000     -43.429  \n",
              "470           -47.000 -36.571     -42.429  \n",
              "\n",
              "[471 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e83a711c-2b61-4abb-aa7b-8f81f34576ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_cases</th>\n",
              "      <th>retail_and_recreation</th>\n",
              "      <th>grocery_and_pharmacy</th>\n",
              "      <th>residential</th>\n",
              "      <th>transit_stations</th>\n",
              "      <th>parks</th>\n",
              "      <th>workplaces</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>1.667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>1.800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1.800</td>\n",
              "      <td>2.800</td>\n",
              "      <td>3.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.333</td>\n",
              "      <td>3.167</td>\n",
              "      <td>3.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.143</td>\n",
              "      <td>1.714</td>\n",
              "      <td>0.714</td>\n",
              "      <td>1.429</td>\n",
              "      <td>3.571</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>173790.0</td>\n",
              "      <td>-61.714</td>\n",
              "      <td>-25.000</td>\n",
              "      <td>24.143</td>\n",
              "      <td>-49.143</td>\n",
              "      <td>-41.000</td>\n",
              "      <td>-45.429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>165553.0</td>\n",
              "      <td>-61.286</td>\n",
              "      <td>-24.429</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-48.714</td>\n",
              "      <td>-40.000</td>\n",
              "      <td>-44.571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>152734.0</td>\n",
              "      <td>-61.143</td>\n",
              "      <td>-24.714</td>\n",
              "      <td>23.714</td>\n",
              "      <td>-49.000</td>\n",
              "      <td>-39.143</td>\n",
              "      <td>-44.286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>127510.0</td>\n",
              "      <td>-60.143</td>\n",
              "      <td>-23.429</td>\n",
              "      <td>23.286</td>\n",
              "      <td>-48.286</td>\n",
              "      <td>-38.000</td>\n",
              "      <td>-43.429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>132788.0</td>\n",
              "      <td>-58.714</td>\n",
              "      <td>-21.143</td>\n",
              "      <td>22.714</td>\n",
              "      <td>-47.000</td>\n",
              "      <td>-36.571</td>\n",
              "      <td>-42.429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>471 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83a711c-2b61-4abb-aa7b-8f81f34576ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e83a711c-2b61-4abb-aa7b-8f81f34576ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e83a711c-2b61-4abb-aa7b-8f81f34576ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "sR-yiL-y8R_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6466cad6-d905-427e-d6db-1feb5923003a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   new_cases  retail_and_recreation  grocery_and_pharmacy  residential  \\\n",
              "0        0.0                  0.667                 1.667        0.000   \n",
              "1        0.0                  0.500                 1.750        0.000   \n",
              "2        0.0                  0.400                 1.800        0.200   \n",
              "3        0.0                  0.500                 2.000        0.000   \n",
              "4        0.0                 -0.143                 1.714        0.714   \n",
              "\n",
              "   transit_stations  parks  workplaces  \n",
              "0             2.000  3.000       3.000  \n",
              "1             2.000  3.250       3.000  \n",
              "2             1.800  2.800       3.200  \n",
              "3             2.333  3.167       3.333  \n",
              "4             1.429  3.571       0.143  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab76034f-2867-4e7f-897c-2f5e27393bc3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>new_cases</th>\n",
              "      <th>retail_and_recreation</th>\n",
              "      <th>grocery_and_pharmacy</th>\n",
              "      <th>residential</th>\n",
              "      <th>transit_stations</th>\n",
              "      <th>parks</th>\n",
              "      <th>workplaces</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.667</td>\n",
              "      <td>1.667</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>1.750</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.000</td>\n",
              "      <td>3.250</td>\n",
              "      <td>3.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.400</td>\n",
              "      <td>1.800</td>\n",
              "      <td>0.200</td>\n",
              "      <td>1.800</td>\n",
              "      <td>2.800</td>\n",
              "      <td>3.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.333</td>\n",
              "      <td>3.167</td>\n",
              "      <td>3.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.143</td>\n",
              "      <td>1.714</td>\n",
              "      <td>0.714</td>\n",
              "      <td>1.429</td>\n",
              "      <td>3.571</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab76034f-2867-4e7f-897c-2f5e27393bc3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab76034f-2867-4e7f-897c-2f5e27393bc3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab76034f-2867-4e7f-897c-2f5e27393bc3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "data = final_df\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07UNYsy08R_l"
      },
      "source": [
        "## Train-Test split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shuffle_df = final_df.sample(frac=1)\n",
        "\n",
        "# Defining a size for train set \n",
        "train_size = int(0.8 * len(final_df))\n",
        "\n",
        "# Splitting dataset \n",
        "train_set = shuffle_df[:train_size]\n",
        "test_set = shuffle_df[train_size:]\n",
        "\n",
        "X_train , Y_train = train_set.drop('new_cases' , axis = 1).values , train_set['new_cases'].values.reshape(-1,1)\n",
        "X_test , Y_test = test_set.drop('new_cases' , axis = 1).values , test_set['new_cases'].values.reshape(-1,1)\n",
        "\n",
        "# print(X_train[:5])\n",
        "# print(Y_train[:5])\n",
        "# print(X_test[:5])\n",
        "# print(Y_test[:5])"
      ],
      "metadata": {
        "id": "9oX9g8GBCBAX"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updated CART Decision Tree Model for Regression using Residual Sum of Squares"
      ],
      "metadata": {
        "id": "BJSFUnr980Yr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQ3h-B968R_h"
      },
      "source": [
        "### Node class for CART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "0OqvwMQd8R_h"
      },
      "outputs": [],
      "source": [
        "class Tree_Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, var_red=None, value=None):\n",
        "        ''' constructor ''' \n",
        "        \n",
        "        # for decision node\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.var_red = var_red\n",
        "        \n",
        "        # for leaf node\n",
        "        self.value = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4LIp__a8R_j"
      },
      "source": [
        "### Tree class for CART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PvLhpB5I8R_j"
      },
      "outputs": [],
      "source": [
        "class CART_DTR():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "              \n",
        "        # initialize the root of the tree \n",
        "        self.root = None\n",
        "        \n",
        "        # stopping conditions\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "               \n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        best_split = {}\n",
        "        # split until stopping conditions are met\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            # check if information gain is positive\n",
        "            if best_split[\"var_red\"]>0:\n",
        "                # recur left\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "                # recur right\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "                # return decision node\n",
        "                return Tree_Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
        "                            left_subtree, right_subtree, best_split[\"var_red\"])\n",
        "        \n",
        "        # compute leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # return leaf node\n",
        "        return Tree_Node(value=leaf_value)\n",
        "\n",
        "    def average(self,col):\n",
        "      #Function to calculate the possible mean values of a Column\n",
        "      l1=[]\n",
        "      for i in range(len(col)-1):\n",
        "        l1.append((col[i]+col[i+1])/2)\n",
        "      return l1\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "              \n",
        "        # dictionary to store the best split\n",
        "        best_split = {}\n",
        "        min_rss = +float(\"inf\")\n",
        "        # print(num_features)\n",
        "        # loop over all the features\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            # calling to get the mean of two consecutive elements of a feature.\n",
        "            possible_thresholds_list=self.average(feature_values.tolist())\n",
        "            possible_thresholds = np.array(possible_thresholds_list)\n",
        "            # print(possible_thresholds)\n",
        "            # loop over all the feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if childs are not null\n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # compute  residual sum of square for both left and right datasets.\n",
        "                    rss_left = self.rss(left_y)\n",
        "                    rss_right=self.rss(right_y)\n",
        "                    curr_rss=rss_left+rss_right\n",
        "                    # update the best split to get the minimum rss out of each posssible thresholds for each feature column.\n",
        "                    if curr_rss<min_rss:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"var_red\"] = curr_rss\n",
        "                        min_rss = curr_rss\n",
        "                        \n",
        "        return best_split\n",
        "    \n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        # ''' function to split the data '''\n",
        "        \n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        return dataset_left, dataset_right\n",
        "\n",
        "    def calculate_leaf_value(self, Y):\n",
        "        # ''' function to compute leaf node '''\n",
        "        val = np.mean(Y)\n",
        "        return val\n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "        # ''' function to train the tree '''\n",
        "        \n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "        \n",
        "    def helper_predict(self, x, tree):\n",
        "        # helper function to traverse through the tree and return the predictions\n",
        "        \n",
        "        if tree.value!=None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.helper_predict(x, tree.left)\n",
        "        else:\n",
        "            return self.helper_predict(x, tree.right)\n",
        "    \n",
        "    def predict(self, X):\n",
        "    # Function to make predictions        \n",
        "        predictions = [self.helper_predict(x, self.root) for x in X]\n",
        "        return predictions\n",
        "    def rss(self,X):\n",
        "      # Function to calculate the rss \n",
        "        mean_data=sum(X)\n",
        "        rss=0\n",
        "        for i in X:\n",
        "          rss=(mean_data-i)**2\n",
        "        return rss"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ID3-A for Regression using Standard Deviation"
      ],
      "metadata": {
        "id": "DDoKJ-HD_BcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, var_red=None, value=None):\n",
        "        \n",
        "        # for decision node\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.var_red = var_red\n",
        "        \n",
        "        # for leaf node\n",
        "        self.value = value"
      ],
      "metadata": {
        "id": "nTp_jjVP_iMy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ID3_A_Regressor():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        \n",
        "        # initialize the root of the tree \n",
        "        self.root = None\n",
        "        \n",
        "        # stopping conditions\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "               \n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        best_split = {}\n",
        "        # split until stopping conditions are met\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "            right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "            # creating the node for best split at this point in the tree\n",
        "            return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
        "                        left_subtree, right_subtree, best_split[\"var_red\"])\n",
        "        \n",
        "        # we are creating a leaf value for each Node, using the leaf_value we are creating our tree.\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # return leaf node\n",
        "        return Node(value=leaf_value)\n",
        "    def average(self,col):\n",
        "      #Function to calculate the possible mean values of a feature that will be used to calculate standard deviation reduction\n",
        "      l1=[]\n",
        "      for i in range(len(col)-1):\n",
        "        l1.append((col[i]+col[i+1])/2)\n",
        "      return l1\n",
        "\n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        # Function that will provide the best split for the data at an instant after calculating sdr for each feature and their possible mean values.\n",
        "        best_split = {}\n",
        "        max_var_red = -float(\"inf\")\n",
        "        # print(num_features)\n",
        "        # loop over all the features\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds_list=self.average(feature_values.tolist())\n",
        "            possible_thresholds = np.array(possible_thresholds_list)\n",
        "            # print(possible_thres)\n",
        "            # loop over all the feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if childs are not null\n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # compute information gain\n",
        "                    curr_var_red = self.var_reduction(y, left_y, right_y)\n",
        "                    # update the best split if needed\n",
        "                    if curr_var_red>max_var_red:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"var_red\"] = curr_var_red\n",
        "                        max_var_red = curr_var_red\n",
        "        return best_split\n",
        "    \n",
        "    def split(self, dataset, feature_index, threshold):       \n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        return dataset_left, dataset_right\n",
        "    \n",
        "    def var_reduction(self, parent, left, right):\n",
        "        \n",
        "        reduction = np.var(parent) - ((len(left) / len(parent)) * np.var(left) + (len(right) / len(parent)) * np.var(right))\n",
        "        return reduction\n",
        "    \n",
        "    def calculate_leaf_value(self, Y):\n",
        "        return  np.mean(Y)\n",
        "                \n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.var_red)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)\n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "                \n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "\n",
        "    def make_prediction(self, x, tree):\n",
        "            \n",
        "        if tree.value!=None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "    \n",
        "    def predict(self, X):      \n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return preditions"
      ],
      "metadata": {
        "id": "tbtWob2Q_PfT"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EXVIV2A8R_o"
      },
      "source": [
        "## Fitting the model for CART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "1rG5sMLh8R_o"
      },
      "outputs": [],
      "source": [
        "cart_regressor = CART_DTR(min_samples_split=3, max_depth=3)\n",
        "cart_regressor.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting the model for ID3-A"
      ],
      "metadata": {
        "id": "L0wNdxs0_uXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id3_regressor = ID3_A_Regressor(min_samples_split=2, max_depth=4)\n",
        "id3_regressor.fit(X_train,Y_train)"
      ],
      "metadata": {
        "id": "ypekBqu__zF7"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJABwDab8R_o"
      },
      "source": [
        "## Testing the created models and calculating their r2score."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_id3 = id3_regressor.predict(X_test) \n",
        "Y_pred_cart = cart_regressor.predict(X_test) "
      ],
      "metadata": {
        "id": "4IaAvnwkAu4k"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "KVbUvnzx8R_p"
      },
      "outputs": [],
      "source": [
        "Y_test=[i[0] for i in Y_test.tolist()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test=np.array(Y_test)\n",
        "Y_pred_id3=np.array(Y_pred_id3)"
      ],
      "metadata": {
        "id": "Q7YeIU32AzAC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_cart=np.array(Y_pred_cart)"
      ],
      "metadata": {
        "id": "akgOplNCdIp1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r2Score(y_pred,y_actual):\n",
        "    sum_square_pred = np.sum((y_pred-y_actual)**2)\n",
        "    sum_squares_actual = np.sum((y_actual- y_actual.mean())**2)\n",
        "    score = (1- sum_square_pred/sum_squares_actual)\n",
        "    return score"
      ],
      "metadata": {
        "id": "SYW4VKu0-zJB"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_id3=r2Score(Y_pred_id3, Y_test)\n",
        "score_id3"
      ],
      "metadata": {
        "id": "FsjYpR3lYUpR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e52fc26-8fb5-4645-b489-85d7c2ebd160"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7715324116794547"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score_cart=r2Score(Y_pred_cart, Y_test)\n",
        "score_cart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_62Sy__NYZp4",
        "outputId": "9a8e7e21-8ecd-43ef-dacb-4a259c72cb88"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6564599519073083"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Means Clustering for classifying the dataset"
      ],
      "metadata": {
        "id": "MQvwA7prAZdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select any 3 random points and Make clusters on them\n",
        "random_indices = np.random.choice(X_train.shape[0], size=3, replace=False)\n",
        "centroids = X_train[random_indices, :]\n",
        "print(centroids)"
      ],
      "metadata": {
        "id": "u-Lq711Aiu79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5111657-2398-4332-ccab-985a818cbb6f"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-60.    -12.857  16.286 -41.857 -51.143 -32.   ]\n",
            " [-56.857  -7.857  15.286 -39.286 -49.571 -32.143]\n",
            " [ -0.571   2.429   0.286   1.143   1.429   5.286]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cluster_ID3():\n",
        "    def __init__(self, centroids , k):\n",
        "        self.root = {}\n",
        "        # Initiate empty clusters\n",
        "        self.clusters_train = {}\n",
        "        self.clusters_label = {}\n",
        "        self.centroid = centroids\n",
        "        self.k = k\n",
        "\n",
        "    def make_clusters(self , X , y, centroids):\n",
        "        # Set the range for value of k (number of centroids)\n",
        "        for i in range(self.k):\n",
        "            self.clusters_train[i] = []\n",
        "            self.clusters_label[i] = []\n",
        "        for i in range(len(X)):\n",
        "            euc_dist = []\n",
        "            for j in range(self.k):\n",
        "                euc_dist.append(np.linalg.norm(X[i] - centroids[j]))\n",
        "            # Append the cluster of data to the dictionary\n",
        "            self.clusters_train[euc_dist.index(min(euc_dist))].append(X[i])\n",
        "            self.clusters_label[euc_dist.index(min(euc_dist))].append(y[i])\n",
        "\n",
        "    def train(self):\n",
        "        for i in range(self.k):\n",
        "            temp = ID3_A_Regressor()\n",
        "            temp.fit(X = self.clusters_train[i] , Y = self.clusters_label[i])\n",
        "            self.root[i] = temp\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            euc_dist = []\n",
        "            for j in range(self.k):\n",
        "                euc_dist.append(np.linalg.norm(X[i] - centroids[j]))\n",
        "            idx = euc_dist.index(min(euc_dist))\n",
        "            # print(idx)\n",
        "            l = []\n",
        "            l.append(X[i])\n",
        "            y_pred.append(self.root[idx].predict(l))\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "moH-eCNQN0tu"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Cluster_ID3(centroids , k = 3)\n",
        "model.make_clusters(X_train , Y_train , centroids)\n",
        "model.train()"
      ],
      "metadata": {
        "id": "fwsUJSDARBLR"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting new_cases using ID3-A after clustering the datapoints."
      ],
      "metadata": {
        "id": "kzEt7gi-U76V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_K_ID3 = model.predict(X_test)\n",
        "print(Y_pred_K_ID3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQcvFANzRBH1",
        "outputId": "78248973-b67c-4d1b-80e6-e9dcb1f824d3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[64188.936170212764], [390766.8], [16425.82], [244924.65], [19869.75], [64188.936170212764], [64188.936170212764], [3222.186440677966], [64188.936170212764], [23946.11111111111], [64188.936170212764], [49131.3], [3222.186440677966], [3222.186440677966], [64188.936170212764], [21051.8], [10.884615384615385], [23946.11111111111], [390766.8], [64188.936170212764], [19869.75], [64188.936170212764], [19869.75], [16425.82], [19869.75], [244924.65], [64188.936170212764], [64188.936170212764], [19869.75], [3222.186440677966], [64188.936170212764], [21051.8], [16425.82], [244924.65], [64188.936170212764], [19869.75], [21051.8], [23946.11111111111], [64188.936170212764], [16425.82], [345931.75], [49131.3], [10.884615384615385], [23946.11111111111], [10.884615384615385], [64188.936170212764], [3222.186440677966], [3222.186440677966], [21051.8], [3222.186440677966], [64188.936170212764], [16425.82], [64188.936170212764], [20934.0], [64188.936170212764], [64188.936170212764], [16425.82], [10.884615384615385], [16425.82], [19869.75], [3222.186440677966], [118579.66666666667], [64188.936170212764], [16425.82], [64188.936170212764], [33825.5], [157227.75], [16425.82], [23946.11111111111], [383979.0], [77930.8], [16425.82], [10.884615384615385], [64188.936170212764], [345931.75], [49131.3], [64188.936170212764], [10.884615384615385], [345931.75], [64188.936170212764], [16425.82], [64188.936170212764], [23946.11111111111], [64188.936170212764], [64188.936170212764], [23946.11111111111], [49131.3], [10.884615384615385], [23946.11111111111], [23946.11111111111], [23946.11111111111], [22132.0], [64188.936170212764], [10.884615384615385], [22132.0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_K_ID3=[i[0] for i in Y_pred_K_ID3]"
      ],
      "metadata": {
        "id": "-R7FqVsXUWZE"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2score_k_id3=r2Score(np.array(Y_pred_K_ID3), Y_test)\n",
        "r2score_k_id3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpf7vTdYS2L7",
        "outputId": "dc6d4f68-6a51-4c01-ac32-6bb10c073404"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9541387476641365"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cluster_Cart():\n",
        "    def __init__(self, centroids , k):\n",
        "        self.root = {}\n",
        "        # Initiate empty clusters\n",
        "        self.clusters_train = {}\n",
        "        self.clusters_label = {}\n",
        "        self.centroid = centroids\n",
        "        self.k = k\n",
        "\n",
        "    def make_clusters(self , X , y, centroids):\n",
        "        # Set the range for value of k (number of centroids)\n",
        "        for i in range(self.k):\n",
        "            self.clusters_train[i] = []\n",
        "            self.clusters_label[i] = []\n",
        "        for i in range(len(X)):\n",
        "            euc_dist = []\n",
        "            for j in range(self.k):\n",
        "                euc_dist.append(np.linalg.norm(X[i] - centroids[j]))\n",
        "            # Append the cluster of data to the dictionary\n",
        "            self.clusters_train[euc_dist.index(min(euc_dist))].append(X[i])\n",
        "            self.clusters_label[euc_dist.index(min(euc_dist))].append(y[i])\n",
        "\n",
        "    def train(self):\n",
        "        for i in range(self.k):\n",
        "            temp = CART_DTR()\n",
        "            temp.fit(self.clusters_train[i] , self.clusters_label[i])\n",
        "            self.root[i] = temp\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = []\n",
        "        for i in range(len(X)):\n",
        "            euc_dist = []\n",
        "            for j in range(self.k):\n",
        "                euc_dist.append(np.linalg.norm(X[i] - centroids[j]))\n",
        "            idx = euc_dist.index(min(euc_dist))\n",
        "            # print(idx)\n",
        "            l = []\n",
        "            l.append(X[i])\n",
        "            y_pred.append(self.root[idx].predict(l))\n",
        "\n",
        "        return y_pred"
      ],
      "metadata": {
        "id": "OvCpoSHxkxLo"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Cluster_Cart(centroids , k = 3)\n",
        "model.make_clusters(X_train , Y_train , centroids)\n",
        "model.train()"
      ],
      "metadata": {
        "id": "XyzsoXZvk0YB"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting new_cases using updated CART model after clustering the datapoints."
      ],
      "metadata": {
        "id": "6qAkqvIDVXEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_K_Cart = model.predict(X_test)\n",
        "print(Y_pred_K_Cart)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNVb5IHwM52m",
        "outputId": "456d2334-57ee-445a-8ada-ddda6bfcfa9d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[30216.441860465115], [243121.0], [32566.69230769231], [243121.0], [30216.441860465115], [30216.441860465115], [50657.8], [21619.2], [50657.8], [9276.25], [74438.22222222222], [29498.533333333333], [21619.2], [21619.2], [91532.06666666667], [16406.17391304348], [9276.25], [32566.69230769231], [375112.0], [50657.8], [30216.441860465115], [50657.8], [30216.441860465115], [20931.55], [30216.441860465115], [21619.2], [50657.8], [50657.8], [30216.441860465115], [21619.2], [30216.441860465115], [16406.17391304348], [85674.6], [375112.0], [68898.85], [30216.441860465115], [16406.17391304348], [16406.17391304348], [74438.22222222222], [22131.571428571428], [50657.8], [29498.533333333333], [9276.25], [9276.25], [9276.25], [74438.22222222222], [21619.2], [29498.533333333333], [16406.17391304348], [21619.2], [50657.8], [32566.69230769231], [68898.85], [29498.533333333333], [50657.8], [68898.85], [20931.55], [9276.25], [16406.17391304348], [30216.441860465115], [21619.2], [89259.2], [74438.22222222222], [20931.55], [68898.85], [29498.533333333333], [161175.66666666666], [16406.17391304348], [9276.25], [383979.0], [20931.55], [16406.17391304348], [9276.25], [50657.8], [245864.16666666666], [29498.533333333333], [245864.16666666666], [9276.25], [50657.8], [30216.441860465115], [16406.17391304348], [91532.06666666667], [9276.25], [68898.85], [50657.8], [9276.25], [29498.533333333333], [9276.25], [32566.69230769231], [9276.25], [9276.25], [166564.44444444444], [74438.22222222222], [9276.25], [166564.44444444444]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred_K_Cart=[i[0] for i in Y_pred_K_Cart]"
      ],
      "metadata": {
        "id": "gRRMKuToT39-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2score_k_cart=r2Score(np.array(Y_pred_K_Cart), Y_test)\n",
        "r2score_k_cart"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUcEa72CTbDI",
        "outputId": "63251561-8b72-413f-ba93-497ae6e29957"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5540781190640378"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BDMbbXt-KerL"
      },
      "execution_count": 74,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "ML-Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g4LIp__a8R_j",
        "9EXVIV2A8R_o"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}